{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d49feba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      "   AUDITOR V14 (CUSTOM EMPTY + MATCHING)\n",
      "==========================================\n",
      "\n",
      "[SCAN] Inventariando 18 archivos en 'input'...\n",
      "  -> [DATOS] all-clinic-sites.csv (ID: CLINIC-SITES)\n",
      "  -> [DATOS] all-companies.csv (ID: COMPANIES)\n",
      "  -> [DATOS] all-contacts.csv (ID: CONTACTS)\n",
      "  -> [DATOS] all-content-resources.csv (ID: CONTENT-RESOURCES)\n",
      "  -> [DATOS] all-deals.csv (ID: DEALS)\n",
      "  -> [DATOS] all-leads.csv (ID: LEADS)\n",
      "  -> [DATOS] all-rewards.csv (ID: REWARDS)\n",
      "  -> [DATOS] all-risk-reports.csv (ID: RISK-REPORTS)\n",
      "  -> [DATOS] all-tickets.csv (ID: TICKETS)\n",
      "  -> [MAPA]  hubspot-properties-export-clinic-sites-2025-12-02.csv (ID: CLINIC-SITES)\n",
      "  -> [MAPA]  hubspot-properties-export-companies-2025-12-01.csv (ID: COMPANIES)\n",
      "  -> [MAPA]  hubspot-properties-export-contacts-2025-12-02.csv (ID: CONTACTS)\n",
      "  -> [MAPA]  hubspot-properties-export-content-resources-2025-12-02.csv (ID: CONTENT-RESOURCES)\n",
      "  -> [MAPA]  hubspot-properties-export-deals-2025-12-02.csv (ID: DEALS)\n",
      "  -> [MAPA]  hubspot-properties-export-leads-2025-12-02.csv (ID: LEADS)\n",
      "  -> [MAPA]  hubspot-properties-export-rewards-2025-12-02.csv (ID: REWARDS)\n",
      "  -> [MAPA]  hubspot-properties-export-risk-reports-2025-12-02.csv (ID: RISK-REPORTS)\n",
      "  -> [MAPA]  hubspot-properties-export-tickets-2025-12-02.csv (ID: TICKETS)\n",
      "\n",
      "--- INICIANDO PROCESO ---\n",
      "\n",
      ">>> Procesando: all-clinic-sites.csv (ID: CLINIC-SITES)\n",
      "    (Mapa detectado: hubspot-properties-export-clinic-sites-2025-12-02.csv)\n",
      "    Cargando mapa: hubspot-properties-export-clinic-sites-2025-12-02.csv\n",
      "    Analizando: all-clinic-sites.csv ...\n",
      "    Buscando duplicados (Fuzzy > 100%)...\n",
      "    Generando Excel: Auditoria_all-clinic-sites.xlsx\n",
      "    [OK] Guardado.\n",
      "\n",
      ">>> Procesando: all-companies.csv (ID: COMPANIES)\n",
      "    (Mapa detectado: hubspot-properties-export-companies-2025-12-01.csv)\n",
      "    Cargando mapa: hubspot-properties-export-companies-2025-12-01.csv\n",
      "    Analizando: all-companies.csv ...\n",
      "    Buscando duplicados (Fuzzy > 100%)...\n",
      "    Generando Excel: Auditoria_all-companies.xlsx\n",
      "    [OK] Guardado.\n",
      "\n",
      ">>> Procesando: all-contacts.csv (ID: CONTACTS)\n",
      "    (Mapa detectado: hubspot-properties-export-contacts-2025-12-02.csv)\n",
      "    Cargando mapa: hubspot-properties-export-contacts-2025-12-02.csv\n",
      "    Analizando: all-contacts.csv ...\n",
      "    Buscando duplicados (Fuzzy > 100%)...\n",
      "    Generando Excel: Auditoria_all-contacts.xlsx\n",
      "    [OK] Guardado.\n",
      "\n",
      ">>> Procesando: all-content-resources.csv (ID: CONTENT-RESOURCES)\n",
      "    (Mapa detectado: hubspot-properties-export-content-resources-2025-12-02.csv)\n",
      "    Cargando mapa: hubspot-properties-export-content-resources-2025-12-02.csv\n",
      "    Analizando: all-content-resources.csv ...\n",
      "    Buscando duplicados (Fuzzy > 100%)...\n",
      "    Generando Excel: Auditoria_all-content-resources.xlsx\n",
      "    [OK] Guardado.\n",
      "\n",
      ">>> Procesando: all-deals.csv (ID: DEALS)\n",
      "    (Mapa detectado: hubspot-properties-export-deals-2025-12-02.csv)\n",
      "    Cargando mapa: hubspot-properties-export-deals-2025-12-02.csv\n",
      "    Analizando: all-deals.csv ...\n",
      "    Buscando duplicados (Fuzzy > 100%)...\n",
      "    Generando Excel: Auditoria_all-deals.xlsx\n",
      "    [OK] Guardado.\n",
      "\n",
      ">>> Procesando: all-leads.csv (ID: LEADS)\n",
      "    (Mapa detectado: hubspot-properties-export-leads-2025-12-02.csv)\n",
      "    Cargando mapa: hubspot-properties-export-leads-2025-12-02.csv\n",
      "    Analizando: all-leads.csv ...\n",
      "    Buscando duplicados (Fuzzy > 100%)...\n",
      "    Generando Excel: Auditoria_all-leads.xlsx\n",
      "    [OK] Guardado.\n",
      "\n",
      ">>> Procesando: all-rewards.csv (ID: REWARDS)\n",
      "    (Mapa detectado: hubspot-properties-export-rewards-2025-12-02.csv)\n",
      "    Cargando mapa: hubspot-properties-export-rewards-2025-12-02.csv\n",
      "    Analizando: all-rewards.csv ...\n",
      "    Buscando duplicados (Fuzzy > 100%)...\n",
      "    Generando Excel: Auditoria_all-rewards.xlsx\n",
      "    [OK] Guardado.\n",
      "\n",
      ">>> Procesando: all-risk-reports.csv (ID: RISK-REPORTS)\n",
      "    (Mapa detectado: hubspot-properties-export-risk-reports-2025-12-02.csv)\n",
      "    Cargando mapa: hubspot-properties-export-risk-reports-2025-12-02.csv\n",
      "    Analizando: all-risk-reports.csv ...\n",
      "    Buscando duplicados (Fuzzy > 100%)...\n",
      "    Generando Excel: Auditoria_all-risk-reports.xlsx\n",
      "    [OK] Guardado.\n",
      "\n",
      ">>> Procesando: all-tickets.csv (ID: TICKETS)\n",
      "    (Mapa detectado: hubspot-properties-export-tickets-2025-12-02.csv)\n",
      "    Cargando mapa: hubspot-properties-export-tickets-2025-12-02.csv\n",
      "    Analizando: all-tickets.csv ...\n",
      "    Buscando duplicados (Fuzzy > 100%)...\n",
      "    Generando Excel: Auditoria_all-tickets.xlsx\n",
      "    [OK] Guardado.\n",
      "\n",
      "[FIN] Todo procesado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from itertools import combinations\n",
    "import csv\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURACIÓN\n",
    "# ==========================================\n",
    "try:\n",
    "    BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_DIR = os.getcwd()\n",
    "\n",
    "INPUT_DIR = os.path.join(BASE_DIR, \"input\")\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, \"output\")\n",
    "\n",
    "def setup_folders():\n",
    "    created = False\n",
    "    for folder in [INPUT_DIR, OUTPUT_DIR]:\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            created = True\n",
    "    return created\n",
    "\n",
    "# ==========================================\n",
    "# 2. DETECCIÓN Y CLASIFICACIÓN\n",
    "# ==========================================\n",
    "\n",
    "def detect_separator(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            return csv.Sniffer().sniff(f.read(4096)).delimiter\n",
    "    except: return ','\n",
    "\n",
    "def clean_filename_key(filename):\n",
    "    f = filename.lower()\n",
    "    f = f.replace('hubspot-properties-export-', '').replace('hubspot-crm-exports-', '').replace('all-', '')\n",
    "    f = re.sub(r'\\d{4}-\\d{2}-\\d{2}', '', f) \n",
    "    f = f.replace('.csv', '').replace('.xlsx', '').replace('.xls', '')\n",
    "    return f.strip('- _')\n",
    "\n",
    "def get_file_type(file_path):\n",
    "    fname = os.path.basename(file_path).lower()\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            headers = pd.read_csv(file_path, sep=detect_separator(file_path), nrows=1).columns.tolist()\n",
    "        else:\n",
    "            headers = pd.read_excel(file_path, nrows=1).columns.tolist()\n",
    "        \n",
    "        h_clean = [str(h).lower().strip() for h in headers]\n",
    "        \n",
    "        # --- TIPO: PROPIEDADES ---\n",
    "        if 'internal name' in h_clean and 'created user' in h_clean:\n",
    "            if 'contact' in fname: obj = \"CONTACTS\"\n",
    "            elif 'compan' in fname: obj = \"COMPANIES\"\n",
    "            elif 'deal' in fname: obj = \"DEALS\"\n",
    "            elif 'ticket' in fname: obj = \"TICKETS\"\n",
    "            else:\n",
    "                obj = clean_filename_key(fname).upper()\n",
    "            return \"PROPERTIES\", obj, file_path\n",
    "\n",
    "        # --- TIPO: DATOS ---\n",
    "        obj_type = None\n",
    "        if 'contact' in fname: obj_type = \"CONTACTS\"\n",
    "        elif 'compan' in fname: obj_type = \"COMPANIES\"\n",
    "        elif 'deal' in fname: obj_type = \"DEALS\"\n",
    "        elif 'ticket' in fname: obj_type = \"TICKETS\"\n",
    "        else:\n",
    "            if 'record id' in h_clean:\n",
    "                obj_type = clean_filename_key(fname).upper()\n",
    "\n",
    "        if obj_type:\n",
    "            return \"DATA\", obj_type, file_path\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  [X] Error leyendo {fname}: {e}\")\n",
    "    \n",
    "    return \"UNKNOWN\", None, None\n",
    "\n",
    "def scan_input_folder():\n",
    "    files = glob.glob(os.path.join(INPUT_DIR, \"*.*\"))\n",
    "    valid_files = [f for f in files if f.lower().endswith(('.csv', '.xlsx', '.xls'))]\n",
    "    props, data = [], []\n",
    "\n",
    "    print(f\"\\n[SCAN] Inventariando {len(valid_files)} archivos en 'input'...\")\n",
    "    for f in valid_files:\n",
    "        ftype, obj, path = get_file_type(f)\n",
    "        if ftype == \"PROPERTIES\":\n",
    "            props.append((obj, path))\n",
    "            print(f\"  -> [MAPA]  {os.path.basename(f)} (ID: {obj})\")\n",
    "        elif ftype == \"DATA\":\n",
    "            data.append((obj, path))\n",
    "            print(f\"  -> [DATOS] {os.path.basename(f)} (ID: {obj})\")\n",
    "    return props, data\n",
    "\n",
    "# ==========================================\n",
    "# 3. LECTURA Y ANÁLISIS\n",
    "# ==========================================\n",
    "\n",
    "def parse_percentage(value):\n",
    "    try:\n",
    "        if pd.isna(value): return 0.0\n",
    "        return float(str(value).strip().replace('%', '')) / 100\n",
    "    except: return 0.0\n",
    "\n",
    "def load_properties_map(file_path):\n",
    "    print(f\"    Cargando mapa: {os.path.basename(file_path)}\")\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path, sep=detect_separator(file_path), encoding='utf-8', low_memory=False)\n",
    "        else:\n",
    "            df = pd.read_excel(file_path)\n",
    "    except: return None\n",
    "\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    col_map = {c.lower(): c for c in df.columns}\n",
    "    \n",
    "    c_int = col_map.get('internal name')\n",
    "    c_user = col_map.get('created user')\n",
    "    c_use = col_map.get('usages')\n",
    "    c_fill = col_map.get('fill rate')\n",
    "\n",
    "    mapping = {}\n",
    "    for _, row in df.iterrows():\n",
    "        internal = str(row[c_int]).strip()\n",
    "        label = str(row[col_map.get('name', '')]).strip() or internal\n",
    "        user = str(row[c_user]).strip()\n",
    "        raw_use = str(row[c_use]).strip() if c_use and pd.notna(row[c_use]) else \"\"\n",
    "        \n",
    "        data = {\n",
    "            'type': 'Default' if user == 'HubSpot' else 'Custom',\n",
    "            'created_by': user,\n",
    "            'is_used': (len(raw_use) > 0 and raw_use != \"0\" and raw_use != \"nan\"),\n",
    "            'usage_detail': raw_use,\n",
    "            'hs_fill': parse_percentage(row[c_fill]) if c_fill else 0.0\n",
    "        }\n",
    "        mapping[internal.lower()] = data\n",
    "        mapping[label.lower()] = data\n",
    "    return mapping\n",
    "\n",
    "def analyze_file(data_path, mapping, threshold):\n",
    "    fname = os.path.basename(data_path)\n",
    "    print(f\"    Analizando: {fname} ...\")\n",
    "    \n",
    "    try:\n",
    "        if data_path.endswith('.csv'):\n",
    "            df = pd.read_csv(data_path, sep=detect_separator(data_path), encoding='utf-8', low_memory=False)\n",
    "        else:\n",
    "            df = pd.read_excel(data_path)\n",
    "    except Exception as e:\n",
    "        print(f\"    [X] Error crítico: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    results = []\n",
    "    for col in df.columns:\n",
    "        key = str(col).strip().lower()\n",
    "        meta = mapping.get(key)\n",
    "        \n",
    "        p_type = meta['type'] if meta else 'Unknown'\n",
    "        user = meta['created_by'] if meta else 'Unknown'\n",
    "        is_used = meta['is_used'] if meta else False\n",
    "        usage_det = meta['usage_detail'] if meta else ''\n",
    "\n",
    "        filled = df[col].count()\n",
    "        unique = df[col].nunique()\n",
    "        total = len(df)\n",
    "        fill_pct = filled / total if total > 0 else 0\n",
    "        \n",
    "        # Ghost: Custom + Con Datos + Sin Uso\n",
    "        is_ghost = (p_type == 'Custom') and (filled > 0) and (not is_used)\n",
    "        # Monotona: Llena + Mismo Valor siempre\n",
    "        is_monotone = (filled > 50) and (unique <= 1)\n",
    "\n",
    "        results.append({\n",
    "            'Property Name': col,\n",
    "            'Type': p_type,\n",
    "            'Created By': user,\n",
    "            'HubSpot Usages': usage_det,\n",
    "            'Is Ghost?': is_ghost,\n",
    "            'Is Monotonic?': is_monotone,\n",
    "            'Fill Rate %': round(fill_pct * 100, 2),\n",
    "            'Filled Rows': filled,\n",
    "            'Unique Values': unique,\n",
    "            'Potential Duplicates': []\n",
    "        })\n",
    "\n",
    "    stats = pd.DataFrame(results)\n",
    "    \n",
    "    print(f\"    Buscando duplicados (Fuzzy > {threshold}%)...\")\n",
    "    dups = []\n",
    "    cols = stats['Property Name'].tolist()\n",
    "    \n",
    "    for c1, c2 in combinations(cols, 2):\n",
    "        r1 = stats[stats['Property Name'] == c1].iloc[0]\n",
    "        r2 = stats[stats['Property Name'] == c2].iloc[0]\n",
    "        if r1['Type'] == 'Default' and r2['Type'] == 'Default': continue\n",
    "        \n",
    "        n1 = c1.lower().replace('_', ' ')\n",
    "        n2 = c2.lower().replace('_', ' ')\n",
    "        score = fuzz.ratio(n1, n2)\n",
    "        \n",
    "        if score >= threshold:\n",
    "            dups.append({'Prop A': c1, 'Type A': r1['Type'], 'Prop B': c2, 'Type B': r2['Type'], 'Score': score})\n",
    "            idx1 = stats.index[stats['Property Name'] == c1][0]\n",
    "            idx2 = stats.index[stats['Property Name'] == c2][0]\n",
    "            stats.at[idx1, 'Potential Duplicates'].append(f\"{c2} ({score}%)\")\n",
    "            stats.at[idx2, 'Potential Duplicates'].append(f\"{c1} ({score}%)\")\n",
    "\n",
    "    return stats, pd.DataFrame(dups)\n",
    "\n",
    "def save_report(stats, dups, original_filename):\n",
    "    clean_name = os.path.splitext(original_filename)[0]\n",
    "    out_name = f\"Auditoria_{clean_name}.xlsx\"\n",
    "    out_path = os.path.join(OUTPUT_DIR, out_name)\n",
    "    \n",
    "    print(f\"    Generando Excel: {out_name}\")\n",
    "    try:\n",
    "        stats['Potential Duplicates'] = stats['Potential Duplicates'].apply(lambda x: \" | \".join(x))\n",
    "        with pd.ExcelWriter(out_path, engine='openpyxl') as writer:\n",
    "            # 1. Todas\n",
    "            stats.to_excel(writer, sheet_name='Todas', index=False)\n",
    "            \n",
    "            # 2. NUEVA: Custom y Vacías (0 fill rate)\n",
    "            # Aquí está lo que pediste: Custom + Vacías\n",
    "            empty_custom = stats[(stats['Type'] == 'Custom') & (stats['Filled Rows'] == 0)]\n",
    "            if not empty_custom.empty:\n",
    "                empty_custom.to_excel(writer, sheet_name='Custom Empty (Delete)', index=False)\n",
    "            \n",
    "            # 3. Ghost (Custom + Datos + Sin Uso)\n",
    "            ghosts = stats[stats['Is Ghost?'] == True].sort_values('Fill Rate %', ascending=False)\n",
    "            if not ghosts.empty: \n",
    "                ghosts.to_excel(writer, sheet_name='Not Used in Automation', index=False)\n",
    "            \n",
    "            # 4. Duplicados\n",
    "            if not dups.empty: \n",
    "                dups.sort_values('Score', ascending=False).to_excel(writer, sheet_name='Potential Duplicates', index=False)\n",
    "            \n",
    "            # 5. Monótonas\n",
    "            monos = stats[stats['Is Monotonic?'] == True]\n",
    "            if not monos.empty: \n",
    "                monos.to_excel(writer, sheet_name='Constant value', index=False)\n",
    "            \n",
    "        print(f\"    [OK] Guardado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"    [X] Error guardando: {e}\")\n",
    "\n",
    "def find_matching_property_file(data_obj_id, data_filename, props_list):\n",
    "    data_key = clean_filename_key(data_filename)\n",
    "    for p_obj, p_path in props_list:\n",
    "        if p_obj == data_obj_id: return p_path\n",
    "    for p_obj, p_path in props_list:\n",
    "        if data_key in os.path.basename(p_path).lower(): return p_path\n",
    "    return None\n",
    "\n",
    "# ==========================================\n",
    "# MAIN LOOP\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"==========================================\")\n",
    "    print(\"   AUDITOR V14 (CUSTOM EMPTY + MATCHING)\")\n",
    "    print(\"==========================================\")\n",
    "    \n",
    "    if setup_folders():\n",
    "        print(\"[!] Carpetas creadas. Pon tus archivos en 'input' y reinicia.\")\n",
    "        sys.exit()\n",
    "\n",
    "    props_list, data_list = scan_input_folder()\n",
    "    \n",
    "    if not props_list or not data_list:\n",
    "        print(\"\\n[!] Faltan archivos en 'input'.\")\n",
    "        sys.exit()\n",
    "\n",
    "    try:\n",
    "        val = input(\"\\nUmbral de similitud (Enter para 92): \").strip()\n",
    "        thresh = int(val) if val else 92\n",
    "    except: thresh = 92\n",
    "\n",
    "    print(\"\\n--- INICIANDO PROCESO ---\")\n",
    "    \n",
    "    for obj_type, data_path in data_list:\n",
    "        fname = os.path.basename(data_path)\n",
    "        clean_name = os.path.splitext(fname)[0]\n",
    "        expected_output = f\"Auditoria_{clean_name}.xlsx\"\n",
    "        \n",
    "        if os.path.exists(os.path.join(OUTPUT_DIR, expected_output)):\n",
    "            print(f\"\\n[SKIP] {fname} ya fue procesado.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n>>> Procesando: {fname} (ID: {obj_type})\")\n",
    "        \n",
    "        best_prop_path = find_matching_property_file(obj_type, fname, props_list)\n",
    "        if not best_prop_path:\n",
    "            best_prop_path = props_list[0][1]\n",
    "            print(f\"    [!] Usando mapa genérico: {os.path.basename(best_prop_path)}\")\n",
    "        else:\n",
    "            print(f\"    (Mapa detectado: {os.path.basename(best_prop_path)})\")\n",
    "\n",
    "        mapping = load_properties_map(best_prop_path)\n",
    "        if mapping:\n",
    "            stats, dups = analyze_file(data_path, mapping, thresh)\n",
    "            if stats is not None:\n",
    "                save_report(stats, dups, fname)\n",
    "\n",
    "    print(\"\\n[FIN] Todo procesado.\")\n",
    "    input(\"Presiona Enter para cerrar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3c204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
